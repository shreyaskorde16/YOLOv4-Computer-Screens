{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDovvy0luh+t+1VCMwjaN4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"d3x91ZJtaDbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","!ln -s '/content/drive/My Drive/' /currdrive"],"metadata":{"id":"m44ZtfKtaEoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/currdrive/yolov4'\n","os.chdir(path)"],"metadata":{"id":"YyOtRNMtaErF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('/currdrive/yolov4/darknet')\n"],"metadata":{"id":"O2vYgfyJaPO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r9BFRzHeaEt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXmYEdaxZ1of"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Load YOLOv4 model\n","net = cv2.dnn.readNetFromDarknet('path/to/yolov4.cfg', 'path/to/yolov4.weights')\n","\n","# Get the output layer names\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# Load video\n","video = cv2.VideoCapture('path/to/video.mp4')\n","\n","# Define classes\n","classes = ['class1', 'class2', 'class3', ...]  # Replace with actual class names\n","\n","while True:\n","    # Read a frame from the video\n","    ret, frame = video.read()\n","\n","    if not ret:\n","        break\n","\n","    # Resize frame to match YOLO input size\n","    height, width, _ = frame.shape\n","    scale = 0.00392\n","    blob = cv2.dnn.blobFromImage(frame, scale, (416, 416), (0, 0, 0), True, crop=False)\n","\n","    # Pass the blob through the network\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    # Initialize empty lists for bounding boxes, confidences, and class IDs\n","    boxes = []\n","    confidences = []\n","    class_ids = []\n","\n","    # Process each output layer\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","\n","            if confidence > 0.5:  # Adjust confidence threshold as needed\n","                # Calculate bounding box coordinates\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                # Add bounding box, confidence, and class ID to respective lists\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","\n","    # Apply non-maximum suppression to eliminate overlapping bounding boxes\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)  # Adjust NMS parameters as needed\n","\n","    # Draw bounding boxes and labels on the frame\n","    for i in indices:\n","        i = i[0]\n","        x, y, w, h = boxes[i]\n","        label = classes[class_ids[i]]\n","        confidence = confidences[i]\n","\n","        # Draw bounding box\n","        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","        # Write label and confidence\n","        cv2.putText(frame, f'{label}: {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Object Tracking', frame)\n","\n","    # Break loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Release resources\n","video.release()\n","cv2.destroyAllWindows()"]}]}